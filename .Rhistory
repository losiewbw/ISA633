Year3 = c(.291, .329),
Combined = c(.300, .298)   # Number of visitors
)
# Print the data frame
print(df)
# Load the data
data <- read.csv("AudioVideo.csv")
# Display the structure of the data
str(data)
# Box plot comparing sales amounts between audio-only and video sales calls
boxplot(Sales_Amount ~ Call_Type, data = data,
xlab = "Call Type", ylab = "Sales Amount",
main = "Sales Amount by Call Type")
# Summary statistics
summary_stats <- aggregate(sales_one_week ~ call_type, data = data, FUN = summary)
print(summary_stats)
# Summary statistics
summary_stats <- aggregate(sales_one_week ~ call_type, data = data, FUN = summary)
print(summary_stats)
# Box plot comparing sales amounts between audio-only and video sales calls
ggplot(data, aes(x = call_type, y = sales_one_week, fill = call_type)) +
geom_boxplot() +
labs(x = "Call Type", y = "Sales Amount", title = "Sales Amount by Call Type")
library(ggplot2)
# Load the data
data <- read.csv("AudioVideo.csv")
# Display the structure of the data
str(data)
# Summary statistics
summary_stats <- aggregate(sales_one_week ~ call_type, data = data, FUN = summary)
print(summary_stats)
# Box plot comparing sales amounts between audio-only and video sales calls
ggplot(data, aes(x = call_type, y = sales_one_week, fill = call_type)) +
geom_boxplot() +
labs(x = "Call Type", y = "Sales Amount", title = "Sales Amount by Call Type")
# Calculate mean and median sales amounts for video sales calls
mean(data$sales_one_week[data$call_type == "video"])
median(data$sales_one_week[data$call_type == "video"])
sd(dif)
sqrt(50/100)
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/ab_revenue.csv", stringsAsFactors = TRUE)
head(df)
library(ggplot2)
data <- read.csv("AudioVideo.csv", stringsAsFactors = TRUE)
head(data)
library(tidyverse)
data %>% group_by(call_type) %>% summarise(mean=mean(sales_one_week), sd=sd(sales_one_week), n=n())
boxplot(sales_one_week~call_type, data=data)
t.test(sales_one_week~call_type, data=data)
samples<-list()
means<-c()
for (i in 1:100){
samples[[i]]<-rnorm(20, 3, 0.5)
means[i]<-mean(samples[[i]])
}
p<-lapply(samples, t.test, conf.level=0.99)
lower<-c()
upper<-c()
for (i in 1:100){
lower[i]<-p[[i]]$conf.int[1]
upper[i]<-p[[i]]$conf.int[2]
}
df1<-data.frame(lower, upper, means)
df1$x<-seq(1:100)
library(ggplot2)
ggplot(df1, aes(x=x, y=means))+geom_point()+geom_errorbar(aes(ymax=upper, ymin=lower))+geom_hline(yintercept = 3, color="red")+ylim(2.4, 3.6)+
theme_bw()+ylab("Confidence Interval")+xlab("Sample Number")
t.test(sales_one_week, data=data)
t.test(sales_one_week~call_type, data=data)
sub<-data %>% filter(call_type=="video")
t.test(sub$sales_one_week)
# Sample data for two groups
groupA <- data$sales_one_week[data$call_type=="audio"]
groupB <- data$sales_one_week[data$call_type=="video"]
# Observed test statistic
observed_statistic <- mean(groupA) - mean(groupB)
# Number of random permutations
num_permutations <- 10000
# Initialize an empty vector to store permutation test statistics
permutation_stats <- numeric(num_permutations)
# Perform random permutations and calculate test statistics
for (i in 1:num_permutations) {
# Combine the data and shuffle the order
combined_data <- c(groupA, groupB)
shuffled_data <- sample(combined_data, replace = FALSE)
# Calculate the test statistic for this permutation
perm_statistic <- mean(shuffled_data[1:length(groupA)]) - mean(shuffled_data[(length(groupA) + 1):(length(groupA) + length(groupB))])
# Store the permutation test statistic
permutation_stats[i] <- perm_statistic
}
# Calculate the p-value
p_value <- mean(abs(permutation_stats) >= abs(observed_statistic))
# Display the p-value
cat("P-value:", p_value, "\n")
data <- read.csv("humana.csv")
# Display the structure of the data
str(data)
# Summary statistics
summary(data)
# Beta-binomial model
# Fit beta-binomial model
bb_model <- betareg(Conversion ~ Variant, data = data)
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
x<-seq(0,1,0.01)
a=2
b=2
fx<-dbeta(x, a, b)
plot(x, fx, type="b")
data <- read.csv("humana.csv", stringsAsFactors = TRUE)
head(data)
data %>% group_by(variant) %>% summarise(mean=mean(conversion), sd=sd(conversion), n=n())
data %>% group_by(variant) %>% summarise(mean=mean(conversion), sum(sum = sum(conversion), sd=sd(conversion), n=n())
data %>% group_by(variant) %>% summarise(mean=mean(conversion), total(sum = sum(conversion), sd=sd(conversion), n=n())
data %>% group_by(variant) %>% summarise(mean=mean(conversion), sum = sum(conversion), sd=sd(conversion), n=n())
prop.test(x=6, n=375)
iter=100000
a=520+1
b=10000+1
a1=837+1
b1=10024+1
count<-c()
for (i in 1:iter){
A<-rbeta(1, a, b)
B<-rbeta(1, a1, b1)
count[i]<-ifelse(A>B, 1, 0)
}
pdiff<-sum(count)/iter
pdiff
iter=100000
a=23+1
b=177+1
a1=28+1
b1=172+1
count<-c()
for (i in 1:iter){
A<-rbeta(1, a, b)
B<-rbeta(1, a1, b1)
count[i]<-ifelse(A>B, 1, 0)
}
pdiff<-sum(count)/iter
pdiff
prop.test(x<-c(520,837), n<-c(10000,10024))
a=3+1
b=197+1
qbeta(0.975, a, b)
qbeta(0.025, a, b)
a=6+1
b=(375-6)+1
qbeta(0.975, a, b)
qbeta(0.025, a, b)
t.test(data$conversion~data$variant)
knitr::opts_chunk$set(echo = TRUE)
df<-read.csv("C:\\Users\\bwlos\\OneDrive\\Documents\\ISA365\\humana_rate.csv")
df<-read.csv("C:\\Users\\bwlos\\OneDrive\\Documents\\ISA365\\humana_rate.csv")
df<-read.csv("C:\\Users\\bwlos\\OneDrive\\Documents\\Spring 2023\\ISA365\\humana_rate.csv")
head(df)
library(tidyverse)
df_long<-df %>% pivot_longer(everything(),
names_to="variant",
values_to="clicks")
head(df_long)
df_long %>% group_by(variant) %>% summarize(mean=mean(clicks))
a=837+1
b=(10024-837)+1
qbeta(0.975, a, b)
qbeta(0.025, a, b)
prop.test(x=837, n=10024)
data <- read.csv("BankData.csv", stringsAsFactors = TRUE)
head(data)
data %>% group_by(version) %>% summarise(mean=mean(y), sum = sum(y), sd=sd(y), n=n()
data %>% group_by(version) %>% summarise(mean=mean(y), sum = sum(y), sd=sd(y), n=n())
data %>% group_by(version) %>% summarise(mean=mean(y), count = count(y), sd=sd(y), n=n())
data %>% group_by(version) %>% summarise(mean=mean(y), sd=sd(y), n=n())
data <- read.csv("BankData.csv", stringsAsFactors = TRUE)
head(data)
summary(data)
data <- read.csv("BankData.csv", stringsAsFactors = TRUE)
head(data)
# Proportion test
# Calculate the number of positive responses for each version
response_counts <- data %>%
group_by(version, y) %>%
summarise(count = n())
# Pivot the data to get counts of positive and negative responses for each version
response_counts_pivot <- response_counts %>%
pivot_wider(names_from = y, values_from = count, values_fill = 0)
# Perform proportion test
prop_test <- prop.test(x = c(response_counts_pivot$`Yes`[response_counts_pivot$version == "A"],
response_counts_pivot$`Yes`[response_counts_pivot$version == "B"]),
n = c(response_counts_pivot$`No`[response_counts_pivot$version == "A"],
response_counts_pivot$`No`[response_counts_pivot$version == "B"]))
# Perform proportion test
prop_test <- prop.test(x = c(response_counts_pivot$`Yes`[response_counts_pivot$version == "A"],
response_counts_pivot$`Yes`[response_counts_pivot$version == "B"]),
n = c(response_counts_pivot$`No`[response_counts_pivot$version == "A"],
response_counts_pivot$`No`[response_counts_pivot$version == "B"]))
data <- read.csv("BankData.csv", stringsAsFactors = TRUE)
head(data)
# Proportion test
# Calculate the number of positive responses for each version
response_counts <- data %>%
group_by(version, y) %>%
summarise(count = n())
# Pivot the data to get counts of positive and negative responses for each version
response_counts_pivot <- response_counts %>%
pivot_wider(names_from = y, values_from = count, values_fill = 0)
# Perform proportion test
prop_test <- prop.test(x = c(response_counts_pivot$`Yes`[response_counts_pivot$version == "A"],
response_counts_pivot$`Yes`[response_counts_pivot$version == "B"]),
n = c(response_counts_pivot$`No`[response_counts_pivot$version == "A"],
response_counts_pivot$`No`[response_counts_pivot$version == "B"]))
is.na(data)
colSums(is.na(data))
data <- read.csv("BankData.csv", stringsAsFactors = TRUE)
head(data)
str(data)
chisq_test <- chisq.test(table(data$y, data$version))
chisq.test(table(data$y, data$version))
chisq.test(table(data$y, data$version))
chisq.test(table(data$y, data$version))
table(bank_data$y, bank_data$version)
table(data$y, data$version)
table(data$y, data$version)
with_loan <- data[data$loan == "yes", ]
with_loan <- data[data$loan == "yes", ]
prop_test_A <- prop.test(table(with_loan$y[with_loan$version == "A"],
without_loan$y[without_loan$version == "A"]))
with_loan <- data[data$loan == "yes", ]
without_loan <- bank_data[bank_data$loan == "no", ]
with_loan <- data[data$loan == "yes", ]
without_loan <- data[data$loan == "no", ]
prop_test_A <- prop.test(table(with_loan$y[with_loan$version == "A"],
without_loan$y[without_loan$version == "A"]))
# Filter data for customers with and without a personal loan
with_loan_A <- bank_data$y[bank_data$loan == "yes" & bank_data$version == "A"]
# Filter data for customers with and without a personal loan
with_loan_A <- data$y[data$loan == "yes" & data$version == "A"]
with_loan_B <- data$y[data$loan == "yes" & data$version == "B"]
without_loan_A <- data$y[data$loan == "no" & data$version == "A"]
without_loan_B <- data$y[data$loan == "no" & data$version == "B"]
# Perform two-sample proportion test for version A
prop_test_A <- prop.test(table(with_loan_A, without_loan_A))
chisq.test(data$y, data$version)
table(data$y, data$version, data$loan)
table(data$y, data$version, n())
table(data$y, data$version)
# Loan = no
prop.test(x<-c(2347,2458), n<-c(19057,19000))
# Loan = yes
prop.test(x<-c(265, 219), n<-c(3625, 3619))
table(data$y, data$version, data$amount > 1500)
# $1500 or less
prop.test(x<-c(1777,1734), n<-c(17290,17026))
# More than $1500
prop.test(x<-c(835,943), n<-c(5392,5503))
table(data$y, data$version, data$housing)
# No housing loan
prop.test(x<-c(1651,1703), n<-c(10100,9981))
# Has a housing loan
prop.test(x<-c(961,974), n<-c(12582,12548))
1-(1 - (0.05/8))**8
1-.95^8
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:1000){
dif[i]<-mean(rnorm(n=50, mean=10, sd=2))
}
hist(dif, breaks=40)
mean(dif)
sd(dif)
2 / sqrt(50)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:100000){
dif[i]<-mean(rnorm(n=500, mean=10, sd=2))
}
hist(dif, breaks=40)
sd(dif) # empirical standard deviation
2/sqrt(500) # theoretical standard deviation
sub<-data %>% filter(call_type=="video")
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:1000){
dif[i]<-mean(rnorm(n=50, mean=10, sd=2))
}
hist(dif, breaks=40)
mean(dif)
sd(dif)
2 / sqrt(50)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:100000){
dif[i]<-mean(rnorm(n=500, mean=10, sd=2))
}
hist(dif, breaks=40)
sd(dif) # empirical standard deviation
2/sqrt(500) # theoretical standard deviation
df <- data.frame(
Player = c("Derek Jeter", "David Justice"),
Year1 = c(.250, .253),  # Batting average
Year2 = c(.314, .321),
Year3 = c(.291, .329),
Combined = c(.300, .298)   # Number of visitors
)
# Print the data frame
print(df)
data <- read.csv("AudioVideo.csv", stringsAsFactors = TRUE)
sub<-data %>% filter(call_type=="video")
library(tidyverse)
sub<-data %>% filter(call_type=="video")
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:1000){
dif[i]<-mean(rnorm(n=50, mean=10, sd=2))
}
hist(dif, breaks=40)
mean(dif)
sd(dif)
2 / sqrt(50)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:100000){
dif[i]<-mean(rnorm(n=500, mean=10, sd=2))
}
hist(dif, breaks=40)
sd(dif) # empirical standard deviation
2/sqrt(500) # theoretical standard deviation
df <- data.frame(
Player = c("Derek Jeter", "David Justice"),
Year1 = c(.250, .253),  # Batting average
Year2 = c(.314, .321),
Year3 = c(.291, .329),
Combined = c(.300, .298)   # Number of visitors
)
# Print the data frame
print(df)
data <- read.csv("AudioVideo.csv", stringsAsFactors = TRUE)
sub<-data %>% filter(call_type=="video")
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:1000){
dif[i]<-mean(rnorm(n=50, mean=10, sd=2))
}
hist(dif, breaks=40)
mean(dif)
sd(dif)
2 / sqrt(50)
set.seed(633)
dif<-c() # initialize a vector for storage
for (i in 1:100000){
dif[i]<-mean(rnorm(n=500, mean=10, sd=2))
}
hist(dif, breaks=40)
sd(dif) # empirical standard deviation
2/sqrt(500) # theoretical standard deviation
df <- data.frame(
Player = c("Derek Jeter", "David Justice"),
Year1 = c(.250, .253),  # Batting average
Year2 = c(.314, .321),
Year3 = c(.291, .329),
Combined = c(.300, .298)   # Number of visitors
)
# Print the data frame
print(df)
data <- read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/AudioVideo.csv", stringsAsFactors = TRUE)
head(data)
library(tidyverse)
data %>% group_by(call_type) %>% summarise(mean=mean(sales_one_week), sd=sd(sales_one_week), n=n())
boxplot(sales_one_week~call_type, data=data)
t.test(sales_one_week~call_type, data=data)
sub<-data %>% filter(call_type=="video")
t.test(sub$sales_one_week)
a=837+1
b=(10024-837)+1
qbeta(0.975, a, b)
qbeta(0.025, a, b)
prop.test(x=837, n=10024)
data <- read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/BankData.csv", stringsAsFactors = TRUE)
head(data)
str(data)
table(data$y, data$version)
chisq.test(data$y, data$version)
table(data$y, data$version, data$loan)
# Loan = no
prop.test(x<-c(2347,2458), n<-c(19057,19000))
# Loan = yes
prop.test(x<-c(265, 219), n<-c(3625, 3619))
table(data$y, data$version, data$housing)
# Has a housing loan
prop.test(x<-c(961,974), n<-c(12582,12548))
prop.test(x=c(961, 974), n=c(11621+961, 11574+974))
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
# Users to achieve 80% power with 5% change in user spend
((2*(1.96 + .7881)^2) * 30^2)/(3.75 * 0.05)^2
## Correct -- I think
# Users to achieve 80% power with 5% change in user spend
((2*(1.96 + .84)^2) * 30^2)/(3.75 * 0.05)^2
# Users to achieve 80% power with 5% change in conversion rate
((2*(1.96 + .84)^2) * (0.05*(1-0.05)))/(0.05*0.05)^2
## Correct
# Users to achieve 80% power with 5% change in conversion rate
((2*(1.96 + .84)^2) * (0.05*(1-0.05)))/(0.05*0.05)^2
results<-c()
d<-c(5, 10, 15, 30, 35, 40, 45, 50, 60, 65)
for(i in 1:length(d)){
results[i]<-power.t.test(delta=d[i], n=100, sd=30, sig.level=0.05, power=NULL)$power
}
plot(d, results, xlab="delta", ylab="power")
abline(h=0.8, col="red")
results<-c()
d<-c(5, 10, 15, 30, 35, 40, 45, 50, 60, 65)
for(i in 1:length(d)){
results[i]<-power.t.test(delta=d[i], n=NULL, sd=30, sig.level=0.05, power=0.8)$n
}
plot(d, results, xlab="delta", ylab="sample size")
results<-c()
d<-c(5, 10, 15, 30, 35, 40, 45, 50, 60, 65)
for(i in 1:length(d)){
results[i]<-power.t.test(delta=d[i], n=NULL, sd=30, sig.level=0.1, power=0.8)$n
}
plot(d, results, xlab="delta", ylab="sample size")
power.prop.test(n=NULL, p1=0.23, p2=0.28, sig.level = 0.05, power=.8)
power.prop.test(n=NULL, p1=0.023, p2=0.023+0.05*0.023, sig.level = 0.05, power=.8)
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
library(tidyverse)
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/zappos.csv")
df_long <- df %>% pivot_longer(everything(),
names_to"treatment",
library(tidyverse)
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/zappos.csv")
df_long <- df %>% pivot_longer(everything(),
names_to = "treatment",
values_to = "spend")
df_long$treatment<- as.factor(df_long$treatment)
df_long %>% group_by(treatment) %>% summarize("mean sales" = mean(spend),
"std sales" = sd(spend), "count" = n())
boxplot(df_long$spend~df_long$treatment)
mod<-aov(spend~treatment, data = df_long)
summary(mod)
library(multcomp)
install.packages("multcomp")
library(multcomp)
tukey<-glht(mod, linfct=mcp(treatments="Tukey"))
library(multcomp)
tukey<-glht(mod, linfct=mcp(treatment="Tukey"))
cld(tukey)
knitr::opts_chunk$set(echo = TRUE,
cache = TRUE,
warning = FALSE,
message = FALSE)
library(tidyverse)
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/zappos.csv")
df_long <- df %>% pivot_longer(everything(),
names_to = "treatment",
values_to = "spend")
df_long$treatment<- as.factor(df_long$treatment)
df_long %>% group_by(treatment) %>% summarize("mean sales" = mean(spend),
"std sales" = sd(spend), "count" = n())
boxplot(df_long$spend~df_long$treatment)
mod<-aov(spend~treatment, data = df_long)
summary(mod)
library(multcomp)
tukey<-glht(mod, linfct=mcp(treatment="Tukey"))
cld(tukey)
summary(tukey)
plot(tukey)
t.test(df$C)
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/uber.csv")
df_long <- df %>% pivot_longer(everything(),
names_to = "treatment",
values_to = "bookings")
df_long$treatment<- as.factor(df_long$treatment)
df_long %>% group_by(treatment, bookings) %>% summarize(n=n()) %>% mutate(freq=n/sum(n))
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/uber.csv")
df_long <- df %>% pivot_longer(everything(),
names_to = "treatment",
values_to = "bookings")
df_long$treatment<- as.factor(df_long$treatment)
df_long %>% group_by(treatment, bookings) %>% summarize(n=n()) %>% mutate(freq=n/sum(n))
full<-glm(bookings~treatment, data=df_long, family="binomial")
anova(full, test="Chisq")
library(multcomp)
comps<-glht(full, linfct = mcp(treatment="Tukey"))
summary(comps)
plot(comps)
0.05/55
1-(1-0.05)^30
