---
title: "Blocking: Continous Response"
date:  "Last complied on `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
  
    toc: true
    toc_float: true
    theme: sandstone
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE, 
                      warning = FALSE,
                      message = FALSE)
```

## Topics Covered

1.  Identifying a blocking variable.

2.  How to account for a blocking variable in an analysis.

3.  How to create proper visualizations of experiments with blocking variables.

4.  The structure of a Randomized Complete Block Design.

5.  Understand the correct degrees of freedom from an analysis in a randomized complete block design.

6.  How to incorporate two blocking variables with a Latin Squares Design.

7.  Understand the structure of a Latin squares design.

8.  Understand the correct degrees of freedom from an analysis of a Latin Squares Design.

9.  Understand the implications of replication and why it is important.

10. Understand the structure of a Generalized complete Block Design.

11. Understand how to analyze a Generalized complete Block design.

## Exercise Experiment

We would like to determine which of the following exercises can be performed the fastest: 10 sit-ups, 10 push-ups, 10 jumping jacks or 10 squats.

## Blocking

In any experiment, as we have seen, variability arising from a nuisance factor can affect the results.

We define this **nuisance factor** or **blocking factor** as a design factor that might have an effect on the response but we are not interested in that effect.

Sometimes this nuisance factor is unknown and uncontrolled--like we don't even know it exists and it may be changing while we perform our experiment. What helps us guard against this type of nuisance?

-   Randomization

But sometimes the nuisance factor is known and controllable, a design technique called **blocking** can be used to systematically eliminate its effect on the statistical comparison among treatments.

So our model for the experiment, a completely randomized design with a blocking factor looks like this:

$$Y_{ij}=\mu+b_i+\tau_j+\epsilon_{ij}$$

We are still interested in testing the equality of treatment means using the treatment effects $\tau_i$.

$H_0$: $\tau_1=\tau_2=...\tau_t$

$H_a$: at least two of the $\tau$s differ

But to ensure that we test against the correct denominator (yard stick) we will partition the effect of the blocks separately. Otherwise the effect of the block gets lumped into the experimental error and our hypothesis testing results can be misleading.

$$ss\text{Total}=ss\text{T}+ ss\text{Blocks}+ ssE$$

-   Every block contained a single replicate of the experiment

The ANOVA table for a blocked experiment looks like this.

![](images/Screenshot%202024-03-19%20133702.png)

-   If you have a blocking factor you always include it in your experiment no matter what

## Experiment with One blocking Factor

A call center for a large rental firm handles customer requests and complaints and uses scripts to help its employees respond to common issues. As the call center is constantly improving efficiency, it often creates new scripts. Three new scripts have been written and the call center wants to know which one allows the agents to resolve the problem the fastest. The current problem of interest is flat tires.

When a customer calls in to report a flat tire, the agent has to make sure the customer is out of harm's way, collect enough information to dispatch a truck and attend to many other minor details. Of course, the agent may well be dealing with irate or distressed customers. The response measure is "number of seconds per flat tire call." Naturally we will choose the script that has the smallest average time per flat tire call.

Incoming calls are randomly assigned to agents. When an agent gets a flat tire call, he enters this information into his computer terminal, and one of the four flat tire scripts is randomly assigned to him. The data is contained in "CallCenter.csv".

What is the treatment variable?

-   The script

What is the response variable?

-   number of seconds per flat tire call

What is the role of agent?

-   Our blocking factor

```{r}
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/CallCenter.csv", stringsAsFactors = TRUE)
df$agent<-as.factor(df$agent)
```

Provide a numerical summary of this data.

```{r}

library(tidyverse)
df %>% group_by(script) %>% summarize("mean"=mean(seconds), "sd"=sd(seconds), "count"=n())

```

Provide a graphical summary of this data.

```{r}

df %>% ggplot(aes(x=agent, y=seconds, group=script))+geom_text(aes(label=script), size=6)+
  xlab("Agent")+ylab("Seconds")+
  theme_bw()+
  theme(axis.title=element_text(size=18))

```

Do you think that the agent reading the script might have an effect on the length of the call?

-   Yes

Clearly the agent makes a difference, but what we really want to know is **is there a script that will decrease the call time, regardless of the agent that reads it?**

Question: Did we randomly assign agent?

-   No

Agent is not a **treatment** that was randomly assigned.

### Analysis of a Randomized Complete Blocked Design

The analysis is simple, you just include the blocking variable in the anova. But, remember that **we only consider the p-value for the randomly assigned treatment variable**.

```{r}

mod1<-aov(seconds~script+agent, data=df) 
summary(mod1)

```

Important: always use the degrees of freedom to check and make sure you did your analysis correctly!

And of course we would want to know which script is best.

```{r}
original_par <- par() #saves the default graphics settings so when we change them to make residual plots or the Tukey plots we can revert.

```

```{r}
library(multcomp)
tukey<-glht(mod1, linfct=mcp(script="Tukey"))
summary(tukey)
par(mar = c(5, 8, 4, 2))
plot(tukey)

```

And of course we would want to run through the assumptions.

```{r}

par( mfrow = c(2,2) )
plot(mod1, which=5)
plot(mod1, which=1)
plot(mod1, which=2)
plot(residuals(mod1) ~ as.factor(script), main="Residuals vs Exp. Unit", font.main=1,data=df)
abline(h = 0, lty = 2)

```

### The Structure of the Blocked design: RCBD

First, we will create a design with a single treatment factor and a single blocking factor in r "by hand". The designs that we have discussed so far are called **Randomized Complete Block Designs** or **RCBD**.

These designs are set up so that each treatment is run within each blocking variable. In fact we are putting a **restriction on randomization** in these designs.

The designs are **completely randomized within each block**. But that is all the randomization that takes place.

-   one replication per block

    -   A replicate is a complete repeat of an experiment

For the call center experiment above we have 6 agents and 4 scripts. Each agent must read each script in a random order.

```{R}
set.seed(13)
script<-factor(c(1,2,3,4))
agent1t <- sample(script,4)
agent2t <- sample(script,4)
agent3t <- sample(script,4)
agent4t <- sample(script,4)
agent5t <- sample(script,4)
agent6t <- sample(script,4)
treatments<-c(agent1t,agent2t, agent3t, agent4t, agent5t, agent6t)
block <- factor( rep(c("agent 1", "agent 2", "agent 3", "agent 4", "agent 5", "agent 6"),each=4))
plan<-data.frame("Agent" = block, "treatment", "Script" = treatments)
plan
```

You can also use the `argicolae` package and the `design.rcbd` function. The `r` value in the `desing.rcbd()` function is the number of replications for the treatments and the number of blocks (since each treatment appears in each block one time)

-   Need to be able to recognize this structure as a RCBD

```{r}

library(agricolae)
script<-c(1,2,3,4)
outdesign <- design.rcbd(script, r=6, seed = 13)
rcb <- outdesign$book
levels(rcb$block) <- c("agent 1", "agent 2", "agent 3", "agent 4", "agent 5", "agent 6")
rcb
```

Now let's simulate some data for an analysis. But the way, this is something I do frequently to check things are set up correctly!

```{r}
set.seed(13)
rcb$y<-round(rnorm(24), digits = 1)
rcb
```

And the key to checking to see if your design is set up correctly is to check the degrees of freedom in your test anova. Notice the `design.rcbd()` function already codes everything appropriately as a factor or numeric.

-   Before running, check that dfs = levels - 1

    -   In this case block should be 5 and script should be 3

```{r}
mod<-aov(y~block+script, data=rcb)
summary(mod)
```

## Experiment with Two Blocking Factors

Suppose we would like to create a plan to study the effect of the number of shelf facings on the the sales of toothpaste in drugstores. The treatment factor is the number of shelf facings (1-4). We wish to use multiple stores in the experiment so we will need to account for that variability. We would also like to account for the calendar week, to adjust for seasonal factors. Our response will be the weekly sales in dollars.

What is the the treatment?

-   \# of shelf facings

What is the response?

-   sales of toothpaste

What are the blocking variables?

-   Store and week

### Latin Squares Designs

Latin Squares Designs can be used whenever there are two independent blocking factors that can be used to group experimental units. It systematically allows [blocking in two directions]{.underline}, so there are [two restrictions]{.underline} on randomization.

In general, a LSD for p treatments is a square containing $p$ rows and $p$ columns. Each of the resulting $p^2$ cells contains one of the treatments.

For example, in a [$p$=5]{.underline} LSD let the letters A, B, C, D, E represent the levels of the treatment. Then the design created is:

![](images/Screenshot%202024-03-19%20140439.png)

The columns represent one blocking factor and the row represent another blocking factor.

In the toothpaste example above we have a $p$=4 LSD. Let's make that design by hand.

Let's make the design using the `agricoale` package and the `design.lsd` function.

```{r}
library(agricolae)
display<-c(1,2,3,4)
outdesign<-design.lsd(display, seed=13)
lsd<-outdesign$book
levels(lsd$row)<-c("Week 1", "Week 2", "Week 3", "Week 4")
levels(lsd$col)<-c("Store 1", "Store 2", "Store 3", "Store 4")
lsd


```

### Analysis of a LSD

The statistical model for a LSD is:

$$Y_{ij}=\mu+r_i+c_j+\tau_k+\epsilon_{ijk}$$

Where now the $r_i$ and $c_j$ are the row and the column blocking factors. All of $i$, $j$ and $k$ range from $1...p$ where p is the number of treatments.

Note: This model is **additive** meaning there is **no interaction between rows, columns and treatments**.

The ANOVA now consists of:

$$ss\text{Total}=ss\text{T}+ ss\text{Rows}+ss\text{Columns}+ ssE$$ where the total df is $p^2-1$ and the error df is $(p-2)(p-1)$ and each the treatments, rows and columns have $(p-1)$ df.

Again, we will only be concerned with the p-value of the treatments, since those are the only things we actually randomly assigned.

After we run the experiment we get this data.

```{R, echo=FALSE}
lsd$sales<-75+3*as.numeric(outdesign$book$row)+4*as.numeric(outdesign$book$col)+10*as.numeric(outdesign$book$display)+rnorm(16,0,3)
lsd$sales<-round(lsd$sales, 2)
```

```{r}
lsd

```

```{r}

lsd %>% ggplot(aes(x=row, y=sales, group=display))+
        geom_text(aes(label=display))+
        facet_grid(~col)+
        theme_bw()+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),axis.title.x = element_blank())+
        ylab("Total Sales")
```

We can run the ANOVA as usual.

```{r}
mod<-aov(sales~row+col+display, data=lsd)
summary(mod)
```

-   Only care about the p-value of the display (the treatment)

And a Tukey HSD

```{r}

par(original_par) #removes the formatting for the residual plots above

```

```{r}
library(multcomp)
tukey<-glht(mod, linfct=mcp(display="Tukey"))
summary(tukey)
par(mar = c(5, 8, 4, 2))
plot(tukey)

```

Check the assumptions, just by the treatment factor.

```{r}

par( mfrow = c(2,2) )
plot(mod1, which=5)
plot(mod1, which=1)
plot(mod1, which=2)
plot(residuals(mod) ~ display, main="Residuals vs Exp. Unit", font.main=1,data=lsd)
abline(h = 0, lty = 2)

```

-   Residuals look ok - small sample size

## Replications

**Replication:** A full repeat of a treatment combination in an experiment.

In our A/B testing and A/B/n testing notes every example experiment had replication. Meaning the treatments were applied to more than one person.

And for obvious reasons, it makes sense to replicate A/B tests. We already know that the larger the sample size you have, the more power you have and that is mostly because the denominator of the tests (the error estimate) decreases with an increased sample size (remember this sentence).

Notice that the two examples we looked at in these notes are small experiments.

The degrees of freedom for error for both of these experiments was small, 15 and 6 accordingly. Much smaller than the larger experiments were were dealing with in the previous notes.

Because of this, there might be a desire to run another **replicate** of the smaller experiments to get better estimates of the error and treatments.

For the script experiment, adding replication would mean adding more agents into the experiment.

For the toothpaste display experiment you could run it over more weeks with more stores, if you have more stores! If not then you can repeat the entire experiment again. Replicate it.

### Example

An auto company wonders which of its three models of car 1, 2, or 3, gets better gas mileage. Gas mileage is affected by fuel type and the speed at which the car is driven. So three common fuel types A, B, and C, and three typical speeds 25, 50 and 75 miles per hour are used as blocking variables. For a specified quantity of fuel, each car is run around a race track until it runs out of gas. Total number of miles traveled is the response variable.

What is the response?

-   total number of miles traveled

What is the treatment?

-   model of car

Are there blocking variables? If so, which one/ones?

-   Yes, fuel type and speed of the car

The data is contained in the "CarData.csv" file.

```{R}

df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/CarData.csv")
df
```

what type of design is this?

-   Latin Squares Design

Is this design replicated? Why or why not?

-   Yes

For fun, let's see what happens if we just analyze a single replicate (we would never do this in the real world). INCORRECT ANALYSIS - DO NOT USE

```{R}
mod<-aov(distance1~speed+fuel+car, data=df)
summary(mod)

```

Now let's analyze this with both replicates, assuming **all 18 treatment combinations were completely randomized and run in a single long experiment.**

First we have to manipulate the data to make it long.

```{R}
df_long<-df %>% pivot_longer(c("distance1", "distance2"),
                             names_to="replicate",
                             values_to="distance")
df_long
```

```{r}
mod<-aov(distance~speed+fuel+car, data=df_long)
summary(mod)

```

-   The mean sq number of the residuals is the denominator of the F-test?

OK, so what if the experiments [ran one replicate on one track and another replicate on another track]{.underline}? Or one replicate one day and another replicate a day next week? We would need to account for the potential variation between replicates. We can do that by adding another blocking factor.

Unless the 18 runs above were randomized and run all together, below is how the experiment should be analyzed.

```{r}
mod<-aov(distance~speed+fuel+car+replicate, data=df_long)
summary(mod)

```

Failing to account for the correct restrictions on randomization could be detrimental to conclusions, and maybe cost your company a lot of money. Don't do it!

## More than one Replicate Per Block

In the script experiment above each agent read each script a single time. In a randomized complete block design there is exactly one replicate per block.

But what if your experiment allows to get more than one replicate per block? Like in a test where your blocks are marketing areas and you are running the same web experiment in each marketing area. You aren't going to just show one person version A and another person version B in each marketing area and call it a day! You will run many replicates of each version in each marketing area.

If that is the case the design is called a **generalized complete block design**. And the analysis changes because we want to make sure that we are always testing against the correct error term.

### Golf Example

Consider an experiment from Golf Magazine. An experiment was conducted to determine the ideal tee height for driving a golf ball as far as possible. The purpose was to recommend to all readers of the article what tee height they should use. The treatment factor was the tee height. An experimental run consisted of a golfer hitting a golf ball from a specified height and the response was the distance the ball traveled. Because the magazine wanted to make a general conclusion, a representative group of golfers was used rather than one golfer. Since the ability to drive the ball by the golfers used in the study differed, it made sense to group or block the trials by golfer and randomize the order that each golfer hit a ball from each of the tee heights.

But since hitting more than three golf balls would probably not fatigue a golfer and cause more variability in the driving distance there was no need to restrict a golfer to hitting just three balls (that would be the RCB, one replicate per golfer).

Instead each golfer hit 5 golf balls from each of 3 tee heights. Nine golfers were used in this part of the study. The data is contained in the golf.csv file.

How many rows will be in this data if it is long?

-   

Make the appropriate variables factors.

```{R}
df<-read.csv("I:\\Classes\\ISA 633\\4. Blocking\\blocking continuous\\golf.csv")
head(df)
df$Tee.Hgt<-as.factor(df$Tee.Hgt)
df$Golfer.ID<-as.factor(df$Golfer.ID)
```

Let's summarize this data.

```{r}

summary<-df %>% group_by(Golfer.ID, Tee.Hgt) %>% summarize("mean Distance"=mean(Distance), "Sd Distance"=sd(Distance), "n"=n())

```

```{R, echo=FALSE}
library(kableExtra)
knitr::kable(
  summary,
  caption="Summary"
  
)%>% kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = F,
                font_size = 12,
                position = "left")

```

And a visualization.

```{R}

df %>% ggplot(aes(x=Golfer.ID, y=Distance, group=interaction(Tee.Hgt, Golfer.ID)))+
        geom_boxplot(aes(color=Tee.Hgt))+
        theme_bw()+
        xlab("Golfer")+
        guides(color = guide_legend(title = "Tee Height")) 
  
        
```

The model for this experiment is a little different. Because now there are *replicate experimental units* in each block it is possible find the block by treatment interaction.

$$Y_{ij}=\mu+b_i+\tau_j+b\tau_{ij}+\epsilon_{ij}$$

But let's think about what we would like to conclude from this study. We want to know which tee height is good for all golfers, not just for an individual golfer.

If the golfer by tee height interaction were significant in this model what would that imply?

-   

Recall the $MSE$ estimates the variation of the response around the treatment mean.

Given that definition above, what does the error term in the model represent? In other words when we use the traditional $MSE$ what are we testing?

-   

So if use the "regular error term" we will not be able to generalize our conclusions to all golfers (from our random sample of golfers).

To generalize to all golfers we would have to ensure that the **treatment factor was significant across the various golfers**. In other words we need a different yardstick for comparison.

-   

That yardstick is going to be $MSE$ for the block by treatment interaction.

This is how we could get R to test what we want.

```{r}
mod <- aov(Distance ~ Tee.Hgt + Error(Golfer.ID/Tee.Hgt), data = df)
summary(mod)
```

Here is the **incorrect way**!!!

```{R}
mod<-aov(Distance~Tee.Hgt*Golfer.ID, data=df)
summary(mod)

```

Let's understand the degrees of freedom for these analyses.

-   There are three tee heights so df=2.

-   There are nine golfers so df=8.

-   The golfer by tee height interaction is 2\*8=16.

-   The residuals are 134-16-8-2=108.

In the first, correct ANOVA above we see that Residuals df=16 which is the df for the interaction, which is what we want to test against.

And of course you would follow by checking assumptions.

## Python Code

You can access the code [here](https://gist.github.com/weeseml/13fcfac35a36aa632d8f7c000b6d86cb). Note I was not able to produce the correct analysis for the Generalized Complete Block design in Python. If you are able to, please share otherwise you will have to use R.

```{r}
library(reticulate)
```

```{python}
import pandas as pd

df = pd.read_csv("I:\\Classes\\ISA 633\\4. Blocking\\blocking continuous\\CallCenter.csv")
df['agent'] = df['agent'].astype('category')
df['script'] = pd.Categorical(df['script'])

```

```{python}

result = df.groupby('script')['seconds'].agg(mean='mean', sd='std', count='count').reset_index()

# Displaying the result
print(result)

```

```{python}
import pandas as pd
from plotnine import ggplot, aes, geom_text, xlab, ylab, theme_bw, theme, element_text

# Creating the plot
plot = (ggplot(df, aes(x='agent', y='seconds', group='script')) +
        geom_text(aes(label='script'), size=8) +
        xlab("Agent") + ylab("Seconds") +
        theme_bw() +
        theme(axis_title=element_text(size=18)))

# Displaying the plot
print(plot)

```

```{python}
import statsmodels.api as sm
from statsmodels.formula.api import ols

# Fit the ANOVA model
mod1 = ols('seconds ~ agent + script', data=df).fit()
anova_results = sm.stats.anova_lm(mod1)

# Display the summary of the ANOVA
print(anova_results)


```

```{python}

import matplotlib.pyplot as plt
import seaborn as sns


# Create a 2x2 subplot
fig, axs = plt.subplots(2, 2, figsize=(12, 10))

# Plot 1: Residuals vs Leverage
sm.graphics.plot_leverage_resid2(mod1, ax=axs[0, 0])

# Plot 2: Residuals vs Fitted
sns.residplot(x=mod1.fittedvalues, y=mod1.resid, lowess=True, ax=axs[0, 1],
              line_kws={'color': 'red', 'lw': 1})
axs[0, 1].set_title('Residuals vs Fitted')
axs[0, 1].set_xlabel('Fitted values')
axs[0, 1].set_ylabel('Residuals')

# Plot 3: Scale-Location
sns.regplot(x=mod1.fittedvalues, y=mod1.resid_pearson, scatter=True,
            ci=False, lowess=True, ax=axs[1, 0], line_kws={'color': 'red', 'lw': 1})
axs[1, 0].set_title('Scale-Location')
axs[1, 0].set_xlabel('Fitted values')
axs[1, 0].set_ylabel('Standardized Residuals')

# Plot 4: Residuals vs Treatment
sns.boxplot(x='script', y=mod1.resid, data=df, ax=axs[1, 1])
axs[1, 1].set_title('Residuals vs Treatment')
axs[1, 1].hlines(0, xmin=-0.5, xmax=1.5, colors='red', linestyles='dashed')

plt.tight_layout()
plt.show()
```

There is no equivavlent to `agricole` in python so I'm only showing the "by hand" method.

```{python}

import numpy as np
np.random.seed(13)

script = np.array([1, 2, 3, 4])

# Sample the script for each agent
agent1t = np.random.choice(script, 4, replace=False)
agent2t = np.random.choice(script, 4, replace=False)
agent3t = np.random.choice(script, 4, replace=False)
agent4t = np.random.choice(script, 4, replace=False)
agent5t = np.random.choice(script, 4, replace=False)
agent6t = np.random.choice(script, 4, replace=False)

# Combine the treatments
treatments = np.concatenate([agent1t, agent2t, agent3t, agent4t, agent5t, agent6t])

# Create the block factor
block = np.repeat(["agent 1", "agent 2", "agent 3", "agent 4", "agent 5", "agent 6"], 4)

# Create the data frame
plan = pd.DataFrame({
    'Agent': block,
    'Script': treatments
})

# Display the plan
print(plan)


```

```{python}

# Set the seed for reproducibility
np.random.seed(13)

# Generate 24 normally distributed random numbers and round them to one decimal place
plan['y'] = np.round(np.random.normal(size=24), 1)

# Display the updated DataFrame
print(plan)


```

```{python}
mod1 = ols('y ~ Agent + Script', data=plan).fit()
anova_results = sm.stats.anova_lm(mod1)

# Display the summary of the ANOVA
print(anova_results)

```

Again, no package so just the "by hand" method.

```{python}

# Set the seed for reproducibility
np.random.seed(13)

# Define the treatments
treatments = np.array([1, 2, 3, 4])

# Function to create a Latin Square Design
def latin_square_design(treatments):
    n = len(treatments)
    lsd = np.zeros((n, n), dtype=int)
    for i in range(n):
        lsd[i] = np.roll(treatments, i)
    np.random.shuffle(lsd.T)  # Transpose and shuffle columns
    return lsd

# Create the Latin Square Design
lsd_array = latin_square_design(treatments)

# Create a DataFrame from the array
lsd = pd.DataFrame(lsd_array, columns=["Store 1", "Store 2", "Store 3", "Store 4"])
lsd.index = ["Week 1", "Week 2", "Week 3", "Week 4"]
lsd.index.name = 'row'

# Display the Latin Square Design
print(lsd)

```

I was lazy and decided to generate the response that I did above, I just needed to re-make the design with numeric factors.

```{python}
 #Set the seed for reproducibility
np.random.seed(13)

# Define the treatments
treatments = np.array([1, 2, 3, 4])

# Function to create a Latin Square Design
def latin_square_design(treatments):
    n = len(treatments)
    lsd = np.zeros((n, n), dtype=int)
    for i in range(n):
        lsd[i] = np.roll(treatments, i)
    np.random.shuffle(lsd.T)  # Transpose and shuffle columns
    return lsd

# Create the Latin Square Design
lsd_array = latin_square_design(treatments)

# Create a DataFrame from the array
lsd = pd.DataFrame(lsd_array, columns=["1", "2", "3", "4"])
lsd.index = ["1", "2", "3", "4"]
lsd.index.name = 'row'

# Display the Latin Square Design
print(lsd)


```

```{python}

import pandas as pd
import numpy as np


# Convert the LSD DataFrame from wide to long format
lsd_long = lsd.reset_index().melt(id_vars='row', var_name='col', value_name='treatment')

# Display the long format DataFrame
print(lsd_long)

```

```{python}

import pandas as pd

# Assuming df is your DataFrame and 'column_name' is the name of the column you want to convert
lsd_long['row'] = pd.to_numeric(lsd_long['row'], errors='coerce')
lsd_long['col'] = pd.to_numeric(lsd_long['col'], errors='coerce')
# Display the updated DataFrame
print(lsd_long)

```

```{python}


import pandas as pd
import numpy as np
# Convert the 'row' and 'col' from categorical to numeric, and use the 'treatment' column for 'display'
lsd_long['sales'] = (75 + 3 * lsd_long['col']
                + 4 * lsd_long['row']
                + 10 * lsd_long['treatment']
                + np.random.normal(0, 3, 16))

# Round the sales values to two decimal places
lsd_long = lsd_long.round(2)

# Display the updated DataFrame
print(lsd_long)

```

```{python}


mod1 = ols('sales ~ row + col+treatment', data=lsd_long).fit()
anova_results = sm.stats.anova_lm(mod1)

# Display the summary of the ANOVA
print(anova_results)

```

```{python}

import statsmodels.api as sm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import matplotlib.pyplot as plt



# Perform Tukey's HSD test
tukey_result = pairwise_tukeyhsd(endog=lsd_long['sales'], groups=lsd_long['treatment'], alpha=0.05)

# Print the summary
print(tukey_result)

tukey_result.plot_simultaneous()
plt.show()
```

```{python}

import pandas as pd

# Reading the CSV file
df = pd.read_csv("golf.csv")

# Displaying the first few rows of the dataframe
print(df.head())


# Rename a column
df = df.rename(columns={'Tee Hgt': 'TeeHgt'})
df = df.rename(columns={'Golfer ID': 'GolferID'})
# Display the DataFrame to verify the change
print(df.head())


# Converting 'Tee.Hgt' and 'Golfer.ID' columns to a categorical data type
df['TeeHgt'] = df['TeeHgt'].astype('category')
df['GolferID'] = df['GolferID'].astype('category')

```

```{python}
import pandas as pd
from plotnine import ggplot, aes, geom_boxplot, theme_bw, xlab, guides, guide_legend



# Create an interaction column
df['interaction'] = df['TeeHgt'].astype(str) + "_" + df['GolferID'].astype(str)

# Creating the plot
plot = (ggplot(df, aes(x='GolferID', y='Distance', group='interaction')) +
        geom_boxplot(aes(color='TeeHgt')) +
        theme_bw() +
        xlab("Golfer") +
        guides(color=guide_legend(title="Tee Height")))

# Displaying the plot
print(plot)


```

Here is as best we can do in python. This model is not exactly what we want, but it is close. Here is the link: <https://www.statsmodels.org/stable/mixed_linear.html>

```{python}
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

# Fit a mixed-effects model
# Tee.Hgt as a fixed effect and Golfer.ID as a random effect
md = smf.mixedlm("Distance ~ TeeHgt", df, groups=df["GolferID"], re_formula="~TeeHgt")
mdf = md.fit()

# Print the summary of the model
print(mdf.summary())


```
