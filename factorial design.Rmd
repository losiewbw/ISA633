---
title: "Factorial Designs"
date:  "Last complied on `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
  
    toc: true
    toc_float: true
    theme: sandstone
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE, 
                      warning = FALSE,
                      message = FALSE)
```

## Topics Covered

1.  Understand the benefits of a factorial design vs. A/B or A/B/n test.

2.  Know how to analyze a factorial design with binary and continuous factors.

3.  Know how to use the final model to find the optimal experimental conditions.

## Example

A company whose sales are made online through a Web page would like to increase the proportion of visitors to their web site that sign up for their service by optimally configuring their web page. In order to buy from the company, customers must sign up and fill out a form supplying their e-mail address along with other required fields. Once a customer signs up, the company has contact information for their database and can e-mail advertisements, special offers, and so forth. The company would like to experiment by testing different configurations of their web page to see if they can increase the number of visitors to their site that actually sign up.

-   Binary response = logistic regression

The factors they wish study were those that change the website appearance.

A: background alternatives with three options

B: font size in the main banner with three sizes

C: text color with two alternatives

D: a choice between a sign-up button or link

What is the response?

-   Sign up or not

-   

What are their experimental options?

-   Build different websites

-   

Why not vary all of the factors at once?

If so then the company would make **3X3X2X2=36 different versions of the webpage**. And they would have to show each version to thousands of users, which seems like a disadvantage.

But, here are the reasons this is a better plan than doing 4 separate A/B or A/B/n tests.

1.  **Interactions**. What if a [certain background alternative worked best with a certain main banner]{.underline}? And the combination actually produced more sign-ups than either option on its own. You could never figure that out with single factor testing.

2.  **Hidden Replication**. Factorial designs require less overall replications. In other words they have more power.

![](images/Screenshot%202024-04-16%20132753.png)

### Creating a Factorial Plan

-   All possible combinations of all of the factors

This is relatively easy, we just need to produce all possible combinations of our factors.

```{R}
d<-expand.grid(Background=c("A", "B", "C"), Font=c(10, 12, 14), Color=c(1, 2), Signup=c("button", "link"))
d
```

Can I hand this to someone to carry out the experiment? What needs to be done?

-   No, the combinations are not randomized

Here is the experiment:

```{r}
library(daewr)
web<-web
web

```

-   The number of signups is still binary, just collapsed so it sums all of the 1s (signups)

How are we going to analyze this experiment?

-   Logistic Regression

What model are we going to fit?

$$log(\frac{p_{ijk}}{1-p_{ijk}})=\mu+\alpha_i+\beta_j+\alpha\beta_{ij}+\gamma_k+\alpha\gamma_{ik}+\beta\gamma_{jk}+\alpha\beta\gamma_{ijk}+\delta_l+$$ $$\alpha\delta_{il}+\beta\delta_{jl}+\alpha\beta\delta_{ijl}+\beta\gamma\delta_{jkl}+\alpha\beta\gamma\delta_{ijkl}$$

$$\alpha = Background Color$$

$$\beta = Font$$

$$\gamma = text color$$

$$\sigma = sign up$$

-   Linear effects (Main Effects), 2 factor interactions, 3 factor interactions, and 4-way interactions

Let's list the degrees of freedom for each main effect:

-   Background = 2

-   Font size = 2

-   Text color = 1

-   Button = 1

What will be the two-factor interactions in the model?

-   Background x Font Size

-   Text Color x Button

What are their corresponding degrees of freedom?

-   2 x 2 = 4

-   1 x 1 = 1

What will be the three-way interactions in the model?

-   Backgorund x Font Size x Text Color = 2 x 2 x 1 = 4

What will be their corresponding degrees of freedom?

-   

-   

The web data is collapsed, summarized. The original response for each replicate was 1 or 0. So each observation is a Bernoulli trial and the aggregate response is binomial with large and approximately equal sample sizes.

We have actual counts this time so we have to tell the `glm` function that. In the past we have had just 0/1 data as the response.

Question: How many observations did the experimental data contain?

-   sum of the visitors column

-   

Below is the same code we have used before.

```{r}
mod<-glm( cbind(signup, visitors-signup) ~ A * B * C * D, data = web, family = binomial )
anova(mod, test="Chisq")
```

-   cbind(success - failures)

-   A \* B \* C \* D = fits all main effects and all possible interactions

For these larger experiments, it is common to reduce the model (remove the terms that are not significant).

-   A reduced model gives better standard error on predictions

When analyzing a model with interactions involved we must adhere to the principle of effect heredity when considering reducing the model.

Consider the interactions to be "children" of the *main effects*. And you can't leave children unattended.

In this case we have a significant three way interaction, so even if the main effects were not significant we would leave A, C, and D in the model. And we would also leave the two factor interactions between A, C, and D.

Here is the reduced model:

```{r}

mod<-glm( cbind(signup, visitors-signup) ~ A * B * C * D-A:B:C:D-B:C:D-A:B:D-A:B:C-B:D-B:C-A:B, data = web, family = binomial )
anova(mod, test="Chisq")
```

The **only** way to interpret this model is with an interaction plot. To use the `sjPlot` package and the `plot_model` function we fudge the model to get the plot we want. Notice below I re-fit the reduced model with A, C and D changed to numeric instead of factors. Note, the anova from this will be completely wrong!! But the plot is easier to read.

```{r}
web$A<-as.numeric(web$A)
web$B<-as.numeric(web$B)
web$C<-as.numeric(web$C)
web$D<-as.numeric(web$D)
mod<-glm( cbind(signup, visitors-signup) ~ A * B * C * D-A:B:C:D-B:C:D-A:B:D-A:B:C-B:D-B:C-A:B, data = web, family = binomial )
library(sjPlot)
plot_model(mod, type="int", axis.title = ("Proportion of Signups"), title="Predicted Probablities of visitor sign-ups")[[4]]
```

So what levels of A, C and D will give us the highest probability of sign ups?

-   A=1, D=2, C=2

```{r}
plot_model(model = mod)
```

## Factorial Design: Continous response

How do you think you would analyze a factorial design with a continuous response?

-   Anova

How would you choose the optimal settings from a factorial design with a continuous response?

-   Interaction plot
-   [Make sure you check your assumptions]{.underline}

### Example

Walmart uses its tests store to try out new ideas. In a recent test, Walmart will build on an experimental checkout experience Walmart previously announced. During this experiment at its test stores, Walmart does away with individual checkout lanes, and transitions cashiers into the role of "hosts" in a new area of the store that resembles a self-checkout destination. Here, customers can opt to check out themselves or have a "host" offer full-service checkout. In either case, store staff are around to help with any issues that arise.

The data for there most recent experiment is contained in the file "Walmart.csv". They measured the average checkout time per day for each combination of stations and hosts.

What is the response?

-   Check out time

What is are the factors?

-   Stations and hosts

-   Station: 2 level factor - 10 or 15

-   Hosts: 3 level factor - 1, 2, of 4

```{R}
df<-read.csv("https://raw.githubusercontent.com/losiewbw/ISA633/main/walmart.csv")
head(df)
```

-   Largest model = station + host + (station x host)

-   This is a randomized complete block design

    -   Within each store we have a full factorial

What should we do with test.store?

-   Block

Is this design replicated?

-   Yes, 3 replicates in each store

Here is a graphical summary.

```{r}
par( mfrow = c(1,2))
boxplot(time~stations, data=df)
boxplot(time~hosts, data=df)
```

We treat the block just the same as we did before. Include it in the model and ignore the p-value. But now because we have 2 factors we can also include the interaction. We stick with the ANOVA here.

```{R}
df$stations<-as.factor(df$stations)
df$hosts<-as.factor(df$hosts)
df$test.store<-as.factor(df$test.store)
mod<-aov(time~test.store+hosts+stations+hosts*stations, data=df)
summary(mod)
```

-   Why can we never take out test store?

    -   We need the sum of squares out of the MSE

    -   Doesn't matter if blocking variable is not significant

Here is the plot from the `sjPlot` package. Its OK.

```{r}

library(sjPlot)
plot_model(mod, type="int")

```

Here is one using base R, I like it better.

```{R}
par( mfrow = c(1,1))
with(df, (interaction.plot(hosts, stations, time, type = "b",
pch = c(18,24,22), leg.bty = "o",
main = "Interaction plot Stations and Hosts",
xlab = "Hosts",ylab = "Time")))


```

Notice the blocking variable (1) is not included in any interaction and (2) it is not included in the interaction plot.

what should you do next?

-   
